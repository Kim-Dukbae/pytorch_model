# MNIST로 생성해보는 숫자 이미지

## Indexs
  - 1.0 ~  Generater와 Discriminator 구현
  - 2.0 ~  model 훈련을 통한 손글씨 데이터 생성해보기
  - 3.0 ~  Generater의 수정을 통한 성능 향상 해보기
    
## 실습 전 내용
생성자는 Latent space 또는 noise vector 라고 불리는 곳에서 다양성을 창출해낸다. 6장에서 Latent space에서의 차원에 따른 생성 이미지의 차이에 대해 더 다루어볼 예정이라서 간략히만 소개하고 넘어가겠습니다.

또한, 모델 소스 코드는 점차 보완해 나가는 과정이기 때문에 처음이 아닌 분들이 보시면 불편하실 수 있습니다.

## 추가적으로 알아두면 좋은 개념
- Linear
- Convolution
- Transpose Convolution, Upsampling
- Binary Cross entropy

  
## 1.1 Generater()
이번에는 생성자 모델을 만들어볼 예정인데, 구현하기 전에 logic 설명부터 하도록 하겠습니다. 

Latent space를 직역하면, 잠재적 공간입니다. 말 그대로 이 공간 속에서는 다양성이 창출될 수 있는 곳입니다. 이 공간에는 무작위 값들이 들어오기 때문에, noise vector라고도 불립니다. 기본적으로 처음 Gan model에서 사용된 Latent space는 1차원 형태의 100개의 값으로 구성이 된 선형층입니다.

하지만 우리가 오늘 해볼 실습은 mnist라는 손글씨 숫자이미지를 생성해볼 예정이기 때문에 1차원을 이미지형태인 차원으로 변환작업을 거쳐야 합니다.

따라서 정리해보면, 생성자 모델은 (100,) 의 Latent space로부터 mnist dataset 형태의 28*28 흑백 이미지를 만들어 내는 모델입니다. 물론 28*28 이미지를 생성하기 위해서는 768개의 1차원 데이터가 필요하다는 건 알고 있다고 생각하겠습니다. 


```python
import torch
import torch.nn as nn

class Linear_Block(nn.Module):
    def __init__(self, in_dim, out_dim):
        super(Linear_Block, self).__init__()
        self.linear = nn.Sequential(
            nn.Linear(in_dim, out_dim, bias=False),
            nn.BatchNorm1d(out_dim),
            nn.LeakyReLU(0.2, inplace=True),
        )
    def forward(self, x):
        return self.linear(x)

class Up_Conv_Block(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(Up_Conv_Block, self).__init__()
        self.upsampling = nn.Sequential(
            nn.ConvTranspose2d( in_ch,  out_ch, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d( out_ch ),
            nn.LeakyReLU(0.2, inplace=True),
        )
    def forward(self, x):
        return self.upsampling(x)

class Generator(nn.Module):
    def __init__(self, latent_dim, img_size):
        super(Generator, self).__init__()

        self.image_size = img_size
        hidden_dim = (self.image_size // 4)**2

        self.latent_space = nn.Sequential(
            Linear_Block(latent_dim, hidden_dim),
            Linear_Block(hidden_dim, hidden_dim)
        )
        self.upsample_layer = nn.Sequential(
            Up_Conv_Block(hidden_dim, hidden_dim//2),
            Up_Conv_Block(hidden_dim//2, hidden_dim//4),
        )
        self.output_layer = nn.Sequential(
            nn.Conv2d( hidden_dim // 4, 1, kernel_size=3, padding=1, bias=False),
            nn.Tanh()
        )
    def forward(self, noise_vector):
        x = self.input_layer(noise_vector)
        x = x.view(-1, self.hidden_dim, self.image_size // 4, self.image_size // 4)  # 4D 변환
        x = self.upsample_layer(x)
        x = self.output_layer(x)
        return x
```

## 1.2 Discriminator()
Generater()로 만든 가짜 손글씨 데이터셋과 실제 손글씨 데이터인 mnist데이터를 토대로 가짜 데이터인지, 진짜 데이터인지 판별하는 판별자 모델 생성을 진행하도록 하겠습니다. 이미지 학습이므로 convolution 층으로 이루어져 있을 예정입니다. 

```python
class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvBlock, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride= 1, bias= False),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.2)
        )
    def forward(self, x):
        return self.conv(x)

class Discriminator(nn.Module):
    def __init__(self, hidden_channels= 32):
        super(Discriminator, self).__init__()
        self.conv1 = ConvBlock(in_channels= 1, out_channels= hidden_channels)
        self.conv2 = ConvBlock(in_channels= hidden_channels, out_channels= hidden_channels*2)
        self.conv3 = ConvBlock(in_channels= hidden_channels*2, out_channels= hidden_channels*4)

        self.max_pool = nn.MaxPool2d(kernel_size= 2, stride= 2)

        self.out = nn.Sequential(
            nn.Linear(hidden_channels*4, 1, bias= False),
            nn.BatchNorm1d(1)
        )

    def forward(self, x):
        x = self.max_pool(self.conv1(x))
        x = self.max_pool(self.conv2(x))
        x = self.max_pool(self.conv3(x))
        x = x.view(x.size(0), -1)
        return self.out(x)

```

## **model 훈련을 통한 손글씨 데이터 생성해보기**
 * 2.0 mnist dataset 준비하기

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# -1에서 1 사이로 정규화 (Tanh와 맞춤)
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))  
])

# MNIST 데이터 로딩
mnist_train_set = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
mnist_test_set = datasets.MNIST(root='./data', train=False, transform=transform, download=True)
```
## 모델 훈련하기

* 1. 생성한 모델을 gpu로 옮겨서 가속화 시킨다.

```python
# GPU 설정
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# model instance 생성 
generator = Generator(latent_dim=100, hidden_dim= 32).to(device)
discriminator = Discriminator(hidden_dim= 32).to(device)
```
* 2. 훈련시 조절할 hyper - parameters 값을 조정한다.

```python
# hyper - parameters
epochs = 30
learning_rate = 0.01

# 모델 훈련 결과 저장
# loss_real_real:  진짜를 진짜로 판단을 잘했는지에 대한 손실값 (최소를 목적)
# loss_fake_fake:  가짜를 가짜로 판단을 잘했는지에 대한 손실값 (최소를 목적)
# loss_fake_real:  가짜를 진짜로 판단을 잘했는지에 대한 손실값 (최대를 목적)
loss_real_real, loss_fake_fake, loss_fake_real = [], [], []
```

* 3. model의 optimizer를 설정해준다. 
 
```python
# 최적화 작업: optimzer, loss
optim_D = optim.Adam(discriminator.parameters(), lr=learning_rate)  # Discriminator 최적화
optim_G = optim.Adam(generator.parameters(), lr=learning_rate)      # Generator 최적화

# Discriminator의 출력단에 sigmoid를 작성하지 않았으므로, BCEWithLogitsLoss 사용.
# 만약 sigmoid를 작성했다면, nn.BCE() 사용.
criterion = nn.BCEWithLogitsLoss()
```

* 4. training.. 주석을 통대 세부 설명.
 
```python
# 1. train 도입 시작 
generator.train(), discriminator.train()
# 2. train을 반복하는 반목문
for epoch in range(epochs):
    # 3. g_loss와 d_loss를 저장하는 list 생성
    epoch_losses = [np.zeros(len(train_loader)) for _ in range(3)]
    # 3. 한 epoch에서 mini batch로 읽어오기 (loader 객체의 label은 무시)
    for i, (real_imgs, _) in enumerate(train_loader):
        # 4. 실제 이미지을 읽어와서 gpu로 옮기기
        real_imgs = real_imgs.to(device)
        # 5. noise_vector 생성 (무작위 값)
        noise_vector = torch.randn(real_imgs.size(0), 100).to(device)
        # 6. 진짜는 1 가짜는 0이라는 one-hot encoding 생성
        real_label = torch.ones(real_imgs.size(0), 1).to(device)
        fake_label = torch.zeros(real_imgs.size(0), 1).to(device)

        # Discriminator 학습
        # --------------------------
        # 7. Discriminator 사용 전 초기화
        optim_D.zero_grad()
        # 8. 실제 이미지 Discriminator에 넣어 예측
        real_pred = discriminator(real_imgs)
        # 9. 실제 이미지를 실제 이미지라고 예측한 손실값 반환
        correct_real = criterion(real_pred, real_label)
        # 10. noise_vector를 generator에 넣어 가짜 이미지 생성
        fake_imgs = generator(noise_vector)
        # 11. discriminator에 가짜 이미지를 넣기 전, 가짜 이미지를 generator를 통해 
        #     생성 되었다는 것을 지워주기 위해 .detach()사용 
        fake_pred = discriminator(fake_imgs.detach())
        # 12. 가짜 이미지를 가짜라고 예측한 손실값 반환
        correct_fake = criterion(fake_pred, fake_label)
        # 13. 최적화를 위한 진짜와 가짜를 잘 분류한 손실값을 평균
        d_loss = (correct_real + correct_fake)/2
        # 14. discriminator의 손실값을 바탕으로 parameters 업데이트
        d_loss.backward()
        optim_D.step()
        # --------------------------
        # Generator 학습
        # 15. Generator 사용 전 초기화
        optim_G.zero_grad()
        # 16. 생성된 가짜 이미지를 discriminator에 넣어서 discriminator가 잘 분류했는지 확인
        #    .detach() 미사용으로 생성 이미지를 암묵적으로 명시함.
        noise_vector = torch.randn(real_imgs.size(0), 100).to(device)
        fake_imgs = generator(noise_vector)
        fake_pred = discriminator(fake_imgs)
        # 17. 가짜 이미지를 실제 이미지로 discriminator에 잘 분류했는지에 대한 손실값.
        # 즉, discriminator를 잘 속일 수 있는 이미지를 생성했는가를 판단
        g_loss = criterion(fake_pred, real_label)          
        # 18. discriminator의 손실값을 바탕으로 parameters 업데이트
        g_loss.backward()
        optim_G.step()

        # 진행 상황 출력 및 저장
        progress_print(i + 1, len(train_loader), epoch, correct_real.item(), correct_fake.item(), g_loss.item())
        epoch_losses[0][i] = correct_real.item()
        epoch_losses[1][i] = correct_fake.item()
        epoch_losses[2][i] = g_loss.item()

    # epoch에 따른 각 배치의 평균 손실값을 저장.
    loss_real_real.append(np.mean(epoch_losses[0]))
    loss_fake_fake.append(np.mean(epoch_losses[1]))
    loss_fake_real.append(np.mean(epoch_losses[2]))

```

* 5. 모델 훈련시, loss값 변동 확인.
 
```python
import matplotlib.pyplot as plt

fig, ax = plt.subplots(ncols=2, figsize=(12, 3))

ax[0].plot(loss_real_real, label='loss_real_real')
ax[0].plot(loss_fake_fake, label='loss_fake_fake')
ax[0].legend()
ax[0].grid()

ax[1].plot(loss_fake_real, label='loss_fake_real')
ax[1].legend()
ax[1].grid()

plt.show()

```

* 6. 모델 결과 확인
     
```python
# 생성할 이미지 수
cnt = 5
noise_vector = torch.randn(cnt, 100,).to(device)

generate_imgs = generator(noise_vector).to('cpu')

import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, cnt, figsize=(cnt * 2, 2))  # cnt개의 이미지를 나란히
for i in range(cnt):
  # print(generate_imgs.shape) # torch.Size([5, 1, 28, 28])
  img = generate_imgs[i].detach()
  img = img.squeeze(0)
  ax[i].imshow(img, cmap= 'gray')
  ax[i].axis('off')  # 축 제거

plt.savefig('result.png')
plt.show()
```

