# MNIST로 생성해보는 숫자 이미지

## Indexs
  - 1.0 ~  Generater와 Discriminator 구현
  - 2.0 ~  model 훈련을 통한 손글씨 데이터 생성해보기
  - 3.0 ~  Generater의 수정을 통한 성능 향상 해보기
    
## 실습 전 내용
생성자는 Latent space 또는 noise vector 라고 불리는 곳에서 다양성을 창출해낸다. 6장에서 Latent space에서의 차원에 따른 생성 이미지의 차이에 대해 더 다루어볼 예정이라서 간략히만 소개하고 넘어가겠습니다.

또한, 모델 소스 코드는 점차 보완해 나가는 과정이기 때문에 처음이 아닌 분들이 보시면 불편하실 수 있습니다.

## 추가적으로 알아두면 좋은 개념
- Linear
- Convolution
- Transpose Convolution, Upsampling
- Binary Cross entropy

  
## 1.1 Generater()
이번에는 생성자 모델을 만들어볼 예정인데, 구현하기 전에 logic 설명부터 하도록 하겠습니다. 

Latent space를 직역하면, 잠재적 공간입니다. 말 그대로 이 공간 속에서는 다양성이 창출될 수 있는 곳입니다. 이 공간에는 무작위 값들이 들어오기 때문에, noise vector라고도 불립니다. 기본적으로 처음 Gan model에서 사용된 Latent space는 1차원 형태의 100개의 값으로 구성이 된 선형층입니다.

하지만 우리가 오늘 해볼 실습은 mnist라는 손글씨 숫자이미지를 생성해볼 예정이기 때문에 1차원을 이미지형태인 차원으로 변환작업을 거쳐야 합니다.

따라서 정리해보면, 생성자 모델은 (100,) 의 Latent space로부터 mnist dataset 형태의 28*28 흑백 이미지를 만들어 내는 모델입니다. 물론 28*28 이미지를 생성하기 위해서는 768개의 1차원 데이터가 필요하다는 건 알고 있다고 생각하겠습니다. 


```python
class Generator(nn.Module):
  def __init__(self, latent_dim= 100):
    super(Generator, self).__init__()
    self.latent_layer = nn.Sequential(
        nn.Linear(latent_dim, 28*28, bias= False),
        nn.BatchNorm1d(28*28),
        nn.LeakyReLU(0.2)
    )

  def forward(self, x):
    x = self.latent_layer(x)
    x = x.view(x.size(0), -1, 28, 28)
    return x
```

## 1.2 Discriminator()
Generater()로 만든 가짜 손글씨 데이터셋과 실제 손글씨 데이터인 mnist데이터를 토대로 가짜 데이터인지, 진짜 데이터인지 판별하는 판별자 모델 생성을 진행하도록 하겠습니다. 이미지 학습이므로 convolution 층으로 이루어져 있을 예정입니다. 

```python
class ConvBlock(nn.Module):
  def __init__(self, in_channels, out_channels):
    super(ConvBlock, self).__init__()
    self.conv = nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride= 1, bias= False),
        nn.BatchNorm2d(out_channels),
        nn.LeakyReLU(0.2)
    )
  def forward(self, x):
    return self.conv(x)

  def forward(self, x):
    return self.conv(x)

class Discriminator(nn.Module):
  def __init__(self, hidden_channels= 32):
    super(Discriminator, self).__init__()
    self.conv = nn.Sequential(
        ConvBlock(in_channels= 1, out_channels= hidden_channels),
        nn.MaxPool2d(kernel_size= 2, stride= 2),
        ConvBlock(in_channels= hidden_channels, out_channels= hidden_channels*2),
        nn.MaxPool2d(kernel_size= 2, stride= 2),
    )
    self.out = nn.Sequential(
        nn.Linear(hidden_channels*2*5*5, 1, bias= False),
        nn.BatchNorm1d(1),
        nn.Tanh()
    )

  def forward(self, x):
    x = self.conv(x)
    x = x.view(x.size(0), -1)
    x = self.out(x)
    return x
```

## **2.0 mnist dataset 준비하기**

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# -1에서 1 사이로 정규화 (Tanh와 맞춤)
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))  
])

# MNIST 데이터 로딩
mnist_train_set = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
mnist_test_set = datasets.MNIST(root='./data', train=False, transform=transform, download=True)
```
## 모델 훈련하기

